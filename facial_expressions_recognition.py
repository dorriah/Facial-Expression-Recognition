# -*- coding: utf-8 -*-
"""Facial_Expressions_Recognition.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1MfGQA-nEIZGNm3QkKK-3Z9nctVNnL4Gy

# **Facial Expression Recognition**

This code shows training two similar models on two different datasets of the same classes. The first dataset is CK+ dataset (https://www.kaggle.com/gauravsharma99/ck48-5-emotions). The other dataset is FER2013 dataset(https://www.kaggle.com/msambare/fer2013).
The datasets contain grayscale images divided into five classes as shown later.
"""

#pip install scikit-plot

#importing needed libraries
import os
import cv2
import math
import numpy as np
from collections import OrderedDict
import scikitplot
import seaborn as sns
from matplotlib import pyplot 

import tensorflow as tf
from tensorflow.keras import optimizers
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Flatten, Dense, Conv2D, MaxPooling2D
from tensorflow.keras.layers import Dropout, BatchNormalization
from tensorflow.keras.callbacks import Callback, EarlyStopping, ReduceLROnPlateau
from keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.utils import plot_model

from keras import backend as K
from keras.utils import np_utils

from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report

#for showing the progress of for loop
from tqdm import tqdm

#connection to google drive
from google.colab import drive
drive.mount('/content/drive')

"""# CK Dataset"""

#counting the number of images in each class and storing them in list for graphing them
images_path = "/content/drive/My Drive/CKdataset/"
myList = dict()
total_images = 0
for dir_ in os.listdir(images_path):
    count = 0
    for f in os.listdir(images_path + dir_ + "/"):
        count += 1
    total_images += count
    myList[dir_] = count
    print(f"{dir_} has {count} number of images")
    
print(f"\ntotal images: {total_images}")

"""`sadness` and `fear` has very low number of images as compared to other classes"""

#graphing number of images in each class
pyplot.bar(myList.keys(), myList.values())

#getting names of classes for using them later.
labels= os.listdir(images_path)

#reading images and storing their pixels in the first array, and their class label in the second array.
img_arr = np.empty(shape=(total_images, 48, 48, 1))
img_label = np.empty(shape=(total_images))
label_to_text = {}

idx = 0
label = 0
for dir_ in os.listdir(images_path):
    if dir_ in  labels:
        for f in tqdm(os.listdir( images_path+ dir_ + "/")):
            img_arr[idx] = np.expand_dims(cv2.imread(images_path + dir_ + "/" + f, 0), axis=2)
            img_label[idx] = label
            idx += 1
        label_to_text[label] = dir_
        label += 1

img_label = np_utils.to_categorical(img_label)

img_arr.shape, img_label.shape, label_to_text

#splitting the dataset into 7:3 for training and testing
X_train, X_test, y_train, y_test = train_test_split(img_arr, img_label, train_size=0.7, stratify=img_label, shuffle=True, random_state=42)
X_train.shape, X_test.shape

#showing some samples of the dataset
fig = pyplot.figure(1, (10,10))

idx = 0
for k in label_to_text:
    sample_indices = np.random.choice(np.where(y_train[:,k]==1)[0], size=5, replace=False)
    sample_images = X_train[sample_indices]
    for img in sample_images:
        idx += 1
        ax = pyplot.subplot(5,5,idx)
        ax.imshow(img.reshape(48,48), cmap='gray')
        ax.set_xticks([])
        ax.set_yticks([])
        ax.set_title(label_to_text[k])
        pyplot.tight_layout()

# data normalization
X_train = X_train / 255.
X_test = X_test / 255.

#generating more images in the training set
train_datagen = ImageDataGenerator(
    rotation_range=15,
    width_shift_range=0.15,
    height_shift_range=0.15,
    shear_range=0.15,
    zoom_range=0.15,
    horizontal_flip=True,
)
train_datagen.fit(X_train)

#defining a function for building CNN model. The model contains:
#input layer, 6 Conv layers, flatten layer, 1 hiddedn dense layer and the out put layer.
def build_dcnn(input_shape, num_classes):
    model_in = Input(shape=input_shape, name="input")
    
    conv2d_1 = Conv2D(
        filters=64,
        kernel_size=(3,3),
        activation='relu',
        padding='same',
        kernel_initializer='he_normal',
        name='conv2d_1'
    )(model_in)
    batchnorm_1 = BatchNormalization(name='batchnorm_1')(conv2d_1)
    conv2d_2 = Conv2D(
        filters=64,
        kernel_size=(3,3),
        activation='relu',
        padding='same',
        kernel_initializer='he_normal',
        name='conv2d_2'
    )(batchnorm_1)
    batchnorm_2 = BatchNormalization(name='batchnorm_2')(conv2d_2)
    
    maxpool2d_1 = MaxPooling2D(pool_size=(2,2), name='maxpool2d_1')(batchnorm_2)
    dropout_1 = Dropout(0.3, name='dropout_1')(maxpool2d_1)

    conv2d_3 = Conv2D(
        filters=128,
        kernel_size=(3,3),
        activation='relu',
        padding='same',
        kernel_initializer='he_normal',
        name='conv2d_3'
    )(dropout_1)
    batchnorm_3 = BatchNormalization(name='batchnorm_3')(conv2d_3)
    conv2d_4 = Conv2D(
        filters=128,
        kernel_size=(3,3),
        activation='relu',
        padding='same',
        kernel_initializer='he_normal',
        name='conv2d_4'
    )(batchnorm_3)
    batchnorm_4 = BatchNormalization(name='batchnorm_4')(conv2d_4)
    
    maxpool2d_2 = MaxPooling2D(pool_size=(2,2), name='maxpool2d_2')(batchnorm_4)
    dropout_2 = Dropout(0.3, name='dropout_2')(maxpool2d_2)

    conv2d_5 = Conv2D(
        filters=256,
        kernel_size=(3,3),
        activation='relu',
        padding='same',
        kernel_initializer='he_normal',
        name='conv2d_5'
    )(dropout_2)
    batchnorm_5 = BatchNormalization(name='batchnorm_5')(conv2d_5)
    conv2d_6 = Conv2D(
        filters=256,
        kernel_size=(3,3),
        activation='relu',
        padding='same',
        kernel_initializer='he_normal',
        name='conv2d_6'
    )(batchnorm_5)
    batchnorm_6 = BatchNormalization(name='batchnorm_6')(conv2d_6)
    
    maxpool2d_3 = MaxPooling2D(pool_size=(2,2), name='maxpool2d_3')(batchnorm_6)
    dropout_3 = Dropout(0.3, name='dropout_3')(maxpool2d_3)

    flatten = Flatten(name='flatten')(dropout_3)
    
    dense_1 = Dense(
        128,
        activation='relu',
        kernel_initializer='he_normal',
        name='dense1'
    )(flatten)
    batchnorm_7 = BatchNormalization(name='batchnorm_7')(dense_1)
    dropout_4 = Dropout(0.4, name='dropout_4')(batchnorm_7)

    model_out = Dense(
        num_classes,
        activation='softmax',
        name='out_layer'
    )(dropout_4)

    model = Model(inputs=model_in, outputs=model_out, name="DCNN")
    
    return model

#compiling and plotting the model.
INPUT_SHAPE = (48, 48, 1)
optim = optimizers.Adam(0.001)

model = build_dcnn(input_shape=(48,48,1), num_classes=len(label_to_text))
model.compile(
        loss='categorical_crossentropy',
        optimizer=optim,
        metrics=['accuracy']
)

plot_model(model, show_shapes=True, show_layer_names=True, expand_nested=True, dpi=50, to_file='model.png')

#prepraing the earcly stopping and number of epochs for training the model.
early_stopping = EarlyStopping(
    monitor='val_loss',
    min_delta=0.00008,
    patience=12,
    verbose=1,
    restore_best_weights=True,
)

lr_scheduler = ReduceLROnPlateau(
    monitor='val_accuracy',
    min_delta=0.0001,
    factor=0.4,
    patience=6,
    min_lr=1e-7,
    verbose=1,
)

callbacks = [
    early_stopping,
    lr_scheduler,
]

batch_size = 10
epochs = 60

#training the first model on the dataset.
history = model.fit_generator(
    train_datagen.flow(X_train, y_train, batch_size=batch_size),
    validation_data=(X_test, y_test),
    steps_per_epoch=len(X_train) / batch_size,
    epochs=epochs,
    callbacks=callbacks,
    use_multiprocessing=True
)

#graphing the accuracy and loss for training and validating the model
sns.set()
fig = pyplot.figure(0, (12, 4))

ax = pyplot.subplot(1, 2, 1)
sns.lineplot(history.epoch, history.history['accuracy'], label='train')
sns.lineplot(history.epoch, history.history['val_accuracy'], label='valid')
pyplot.title('Accuracy')
pyplot.tight_layout()

ax = pyplot.subplot(1, 2, 2)
sns.lineplot(history.epoch, history.history['loss'], label='train')
sns.lineplot(history.epoch, history.history['val_loss'], label='valid')
pyplot.title('Loss')
pyplot.tight_layout()

pyplot.savefig('epoch_history.png')
pyplot.show()

#showing the number that represents each class.
label_to_text

#making a dictionary for each class and its correspending number.
text_to_label = dict((v,k) for k,v in label_to_text.items())
text_to_label

#evaluating the model on the validation set and printing the results and confusion matrix.
yhat_test = model.predict(X_test)
yhat_test = np.argmax(yhat_test, axis=1)
ytest_ = np.argmax(y_test, axis=1)

scikitplot.metrics.plot_confusion_matrix(ytest_, yhat_test, figsize=(7,7))
pyplot.savefig("confusion_matrix_model3pipes.png")

test_accu = np.sum(ytest_ == yhat_test) / len(ytest_) * 100
print(f"test accuracy: {round(test_accu, 4)} %\n\n")

print(classification_report(ytest_, yhat_test))

"""# FER Dataset"""

#counting the images in each class of the second dataset
images2_path = "/content/drive/My Drive/FERdataset/"
myList2 = dict()
total_images2 = 0
for dir_ in os.listdir(images2_path):
    count2 = 0
    for f in os.listdir(images2_path + dir_ + "/"):
        count2 += 1
    total_images2 += count2
    myList2[dir_] = count2
    print(f"{dir_} has {count2} number of images")
    
print(f"\ntotal images: {total_images2}")

#plotting the number of images in each class.
pyplot.bar(myList2.keys(), myList2.values())

#getting names of classes to use them later.
labels2= os.listdir(images2_path)

#reading images in each class and storing their pixels and their labels in arrays,
img_arr2 = np.empty(shape=(total_images2, 48, 48, 1))
img_label2 = np.empty(shape=(total_images2))
label_to_text2 = {}

idx2 = 0
label2 = 0
for dir_ in os.listdir(images2_path):
    if dir_ in  labels2:
        for f in tqdm(os.listdir( images2_path+ dir_ + "/")):
            img_arr2[idx2] = np.expand_dims(cv2.imread(images2_path + dir_ + "/" + f, 0), axis=2)
            img_label2[idx2] = label2
            idx2 += 1
        label_to_text2[label2] = dir_
        label2 += 1

img_label2 = np_utils.to_categorical(img_label2)

img_arr2.shape, img_label2.shape, label_to_text2

#splitting the dataset into 7:3 training and testing
X_train2, X_test2, y_train2, y_test2 = train_test_split(img_arr2, img_label2, train_size=0.7, stratify=img_label2, shuffle=True, random_state=42)
X_train2.shape, X_test2.shape

#showing some samples of the dataset
fig = pyplot.figure(1, (10,10))

idx = 0
for k in label_to_text2:
    sample_indices = np.random.choice(np.where(y_train2[:,k]==1)[0], size=5, replace=False)
    sample_images = X_train2[sample_indices]
    for img in sample_images:
        idx += 1
        ax = pyplot.subplot(5,5,idx)
        ax.imshow(img.reshape(48,48), cmap='gray')
        ax.set_xticks([])
        ax.set_yticks([])
        ax.set_title(label_to_text2[k])
        pyplot.tight_layout()

# data normalization
X_train2 = X_train2 / 255.
X_test2 = X_test2 / 255.

#generating more images for training set.
train_datagen2 = ImageDataGenerator(
    rotation_range=15,
    width_shift_range=0.15,
    height_shift_range=0.15,
    shear_range=0.15,
    zoom_range=0.15,
    horizontal_flip=True,
)
train_datagen2.fit(X_train2)

#compiling model 2
INPUT_SHAPE = (48, 48, 1)
optim = optimizers.Adam(0.001)

model2 = build_dcnn(input_shape=(48,48,1), num_classes=len(label_to_text2))
model2.compile(
        loss='categorical_crossentropy',
        optimizer=optim,
        metrics=['accuracy']
)

#training model 2
history2 = model2.fit_generator(
    train_datagen2.flow(X_train2, y_train2, batch_size=batch_size),
    validation_data=(X_test2, y_test2),
    steps_per_epoch=len(X_train2) / batch_size,
    epochs=epochs,
    callbacks=callbacks,
    use_multiprocessing=True
)

#graphing the accuracy and loss for training and validation of model 2
sns.set()
fig = pyplot.figure(0, (12, 4))

ax = pyplot.subplot(1, 2, 1)
sns.lineplot(history2.epoch, history2.history['accuracy'], label='train')
sns.lineplot(history2.epoch, history2.history['val_accuracy'], label='valid')
pyplot.title('Accuracy')
pyplot.tight_layout()

ax = pyplot.subplot(1, 2, 2)
sns.lineplot(history2.epoch, history2.history['loss'], label='train')
sns.lineplot(history2.epoch, history2.history['val_loss'], label='valid')
pyplot.title('Loss')
pyplot.tight_layout()

pyplot.savefig('epoch_history2.png')
pyplot.show()

#showing the number that represents each class.
label_to_text2

#making a dictionary for each class and its correspending number.
text_to_label2 = dict((v,k) for k,v in label_to_text2.items())
text_to_label2

#evalauting model 2 and showing results and confusion matrix
yhat_test2 = model2.predict(X_test2)
yhat_test2 = np.argmax(yhat_test2, axis=1)
ytest_2 = np.argmax(y_test2, axis=1)

scikitplot.metrics.plot_confusion_matrix(ytest_2, yhat_test2, figsize=(7,7))
pyplot.savefig("confusion_matrix_model3pipes2.png")

test_accu2 = np.sum(ytest_2 == yhat_test2) / len(ytest_2) * 100
print(f"test accuracy: {round(test_accu2, 4)} %\n\n")

print(classification_report(ytest_2, yhat_test2))